{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fc79f7-e5eb-4510-b1fc-d0950a2d2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a670273a-46e6-4a0d-95f8-d9fd9d19c013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle as pkl\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import MeanSquaredError\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84439722-8d97-4ffa-b1df-242bc0d52d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../' * 2)\n",
    "\n",
    "from continual_learning.models.autoencoder.omniglot import OmniglotAutoencoderModel, OmniglotAutoencoder, ThresholdStopping\n",
    "from settings import DATASETS_DIR, MODELS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca5d3ce-5f15-409f-81a3-cfed967396b5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a844245-2e62-4695-abee-4b7e94b61e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_OUTPUT_PATH = MODELS_DIR / 'ensemble_omniglot_autoencoder' / 'encoder.ckpt'\n",
    "OMNIGLOT_DATASET_DIR = DATASETS_DIR / 'omniglot'\n",
    "MNIST_DATASET_DIR = DATASETS_DIR / 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f42a3b6-85c6-4e77-becd-c42f546f3d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "ENCODER_SIZE = 512\n",
    "INPUT_SIZE = 28\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 48\n",
    "BATCH_SIZE_TEST = 256\n",
    "# Training\n",
    "MAX_EPOCHS = -1\n",
    "LOSS_THRESHOLD = 0.020\n",
    "THRESHOLD_METRIC = 'val/reconstruction_loss'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4665d1d7-c150-4942-af4e-996b7815a687",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2bf22b-f55a-41ea-bcd5-a1231e9e66a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "OMNIGLOT_DATASET_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffe1f49-562d-4824-976d-f8b8c46a5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.Omniglot(\n",
    "    root=OMNIGLOT_DATASET_DIR,\n",
    "    download=True,\n",
    "    background=True,\n",
    "    transform=Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Resize((28, 28)),\n",
    "        torchvision.transforms.Lambda(lambda x: 1.0 - x)\n",
    "    ])\n",
    ")\n",
    "val_dataset = torchvision.datasets.Omniglot(\n",
    "    root=OMNIGLOT_DATASET_DIR,\n",
    "    download=True,\n",
    "    background=False,\n",
    "    transform=Compose([\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Resize((28, 28)),\n",
    "        torchvision.transforms.Lambda(lambda x: 1.0 - x)\n",
    "    ])\n",
    ")\n",
    "\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE_TEST)\n",
    "\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc156181-e9d4-4cf7-9a67-a9621f721194",
   "metadata": {},
   "source": [
    "## Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7a8d4-3f06-441c-9686-d332fe6eef84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = OmniglotAutoencoderModel(encoder_size=28)\n",
    "autoencoder = OmniglotAutoencoder(input_size=INPUT_SIZE, encoder_size=ENCODER_SIZE, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c23fd8-b839-4cda-a080-9c9010c727a5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c2f3d-e374-496d-9a1d-30964c62cd87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    progress_bar_refresh_rate=10,\n",
    "    enable_progress_bar=True,\n",
    "    enable_checkpointing=False,\n",
    "    checkpoint_callback=False,\n",
    "    logger=True,\n",
    "    weights_summary=None,\n",
    "    callbacks=[ThresholdStopping(metric=THRESHOLD_METRIC, threshold=LOSS_THRESHOLD)],\n",
    ")\n",
    "\n",
    "trainer.fit(autoencoder, train_data_loader, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25de0388-097e-45b7-a94d-91f1677d00e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.callback_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8bfd15-73d2-405f-bffb-7c14734eb802",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce59fdc-2ee0-4a7b-b969-bd3d1604cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER_OUTPUT_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "trainer.save_checkpoint(ENCODER_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4046d0-696b-4f6b-bc61-caad6e84a647",
   "metadata": {},
   "source": [
    "Load the model (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423ac26c-86f7-4ebd-8dfa-87cac589b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = OmniglotAutoencoder.load_from_checkpoint(checkpoint_path=ENCODER_OUTPUT_PATH, input_size=INPUT_SIZE, encoder_size=ENCODER_SIZE, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdffe57-d41c-45b5-9b64-ff2ed4ccaea3",
   "metadata": {},
   "source": [
    "## Verifying reconstruction quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503dd850-005b-4b13-a4cf-fa2182b682c7",
   "metadata": {},
   "source": [
    "### Comparison with original examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85664734-663e-4bd9-a3f5-137f1298a991",
   "metadata": {},
   "outputs": [],
   "source": [
    "originals = []\n",
    "encodings = []\n",
    "reconstructions = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for items, batch_labels in train_data_loader:\n",
    "        reconstruction, joint_encoding, tanh_encoding, relu_encoding = autoencoder.model.forward(items)\n",
    "        reconstructions.append(reconstruction.squeeze())\n",
    "        labels.extend(batch_labels)\n",
    "        originals.append(items.squeeze())\n",
    "        encodings.append(joint_encoding)\n",
    "\n",
    "    reconstructions = torch.cat(reconstructions, dim=0)\n",
    "    labels = [label.item() for label in labels]\n",
    "    originals = torch.cat(originals, dim=0)\n",
    "    encodings = torch.cat(encodings, dim=0)\n",
    "    \n",
    "print(f\"Original images: {np.shape(originals)}\")\n",
    "print(f\"Reconstructions: {np.shape(reconstructions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa978b-3e7b-4ecd-a855-94753e43d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(25, 6), nrows=2, ncols=5)\n",
    "\n",
    "indexes_to_show = (0, 5)\n",
    "for index, img_index in enumerate(range(*indexes_to_show)):\n",
    "    axs[0][index].imshow(originals[img_index])\n",
    "    axs[1][index].imshow(reconstructions[img_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b912cde-28e2-4591-9769-83a2dda7d188",
   "metadata": {},
   "source": [
    "### Encoding MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec6a304-ef20-48f6-9eaf-64dafd0c5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_train_dataset = torchvision.datasets.MNIST(\n",
    "#     root=MNIST_DATASET_DIR,\n",
    "#     download=True,\n",
    "#     train=True,\n",
    "#     transform=Compose([\n",
    "#         torchvision.transforms.ToTensor(),\n",
    "#         torchvision.transforms.Resize((28, 28)),\n",
    "#     ])\n",
    "# )\n",
    "\n",
    "# mnist_test_dataset = torchvision.datasets.MNIST(\n",
    "#     root=MNIST_DATASET_DIR,\n",
    "#     download=True,\n",
    "#     train=False,\n",
    "#     transform=Compose([\n",
    "#         torchvision.transforms.ToTensor(),\n",
    "#         torchvision.transforms.Resize((28, 28)),\n",
    "#     ])\n",
    "# )\n",
    "\n",
    "# mnist_data_loader_train = DataLoader(mnist_train_dataset, BATCH_SIZE)\n",
    "# mnist_data_loader_test = DataLoader(mnist_test_dataset, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c822a82-f6f9-4910-8a8b-4866be42f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset_train = torchvision.datasets.MNIST(\n",
    "    root=OMNIGLOT_DATASET_DIR,\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=Compose([\n",
    "        ToTensor(),\n",
    "#         Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    ")\n",
    "mnist_dataset_test = torchvision.datasets.MNIST(\n",
    "    root=OMNIGLOT_DATASET_DIR,\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=Compose([\n",
    "        ToTensor(),\n",
    "#         Normalize((0.1307,), (0.3081,)),\n",
    "    ])\n",
    ")\n",
    "mnist_data_loader_train = DataLoader(mnist_dataset_train, batch_size=48)\n",
    "mnist_data_loader_test = DataLoader(mnist_dataset_test, batch_size=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addf1ead-e5dc-4896-9c60-fe65081e302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_encodings = []\n",
    "# mnist_labels = []\n",
    "\n",
    "# for items, batch_labels in mnist_data_loader_train:\n",
    "#     tanh_encoding, relu_encoding = autoencoder.model.encode(items)\n",
    "#     mnist_encodings.append(tanh_encoding)\n",
    "#     mnist_labels.extend(batch_labels)\n",
    "    \n",
    "# mnist_labels = [label.item() for label in mnist_labels]\n",
    "# mnist_encodings = torch.cat(mnist_encodings, dim=0).detach().numpy()\n",
    "\n",
    "# print(mnist_encodings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa90af3f-3b4b-4672-94af-191333360a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_encodings_test = []\n",
    "mnist_labels_test = []\n",
    "\n",
    "for items, batch_labels in tqdm(mnist_data_loader_test, total=len(mnist_data_loader_test)):\n",
    "    tanh_encoding, relu_encoding = autoencoder.model.encode(items)\n",
    "    mnist_encodings_test.append(tanh_encoding)\n",
    "    mnist_labels_test.extend(batch_labels)\n",
    "    \n",
    "mnist_labels_test = [str(label.item()) for label in mnist_labels_test]\n",
    "mnist_encodings_test = torch.cat(mnist_encodings_test, dim=0).detach().numpy()\n",
    "\n",
    "print(mnist_encodings_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b42a6ec-dddf-4860-8b8f-2d7d777ffad7",
   "metadata": {},
   "source": [
    "T-SNE embeddings of MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a2d5c6-5c0a-4265-bee1-1cdd05b0ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_embedded_train = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(mnist_encodings[:10000])\n",
    "X_embedded_test = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(mnist_encodings_test)\n",
    "\n",
    "# X_embedded_train.shape\n",
    "X_embedded_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5655b1de-ea70-49b0-a537-9807a8d28d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_sorted = np.argsort(mnist_labels_test)\n",
    "mnist_labels_test = np.array(mnist_labels_test)[arg_sorted]\n",
    "X_embedded_test = X_embedded_test[arg_sorted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e63fb-2a4b-4b1b-aa73-5ea57742839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "# ax_train = sns.scatterplot(\n",
    "#     x=X_embedded_train[:, 0],\n",
    "#     y=X_embedded_train[:, 1],\n",
    "#     hue=mnist_labels[:10000],\n",
    "#     palette=\"gist_rainbow\",\n",
    "#     ax=axs[0],\n",
    "# )\n",
    "ax_test = sns.scatterplot(\n",
    "    x=X_embedded_test[:, 0],\n",
    "    y=X_embedded_test[:, 1],\n",
    "    hue=mnist_labels_test,\n",
    "    palette=\"gist_rainbow\",\n",
    ")\n",
    "handles, labels = ax_test.get_legend_handles_labels()\n",
    "ax_test.legend(handles, labels, title='Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd3444-82db-4163-a64e-ba93cd99c694",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Offline baselines on encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e9714-9247-4dfc-a7d9-cef801a19fe6",
   "metadata": {},
   "source": [
    "MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24650d92-9520-48ee-bdb6-a056f2c5c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(), learning_rate_init=0.001, verbose=False, early_stopping=True, max_iter=500)\n",
    "clf.fit(mnist_encodings, mnist_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b4696-fe99-4683-9cac-49e0bf899b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(mnist_encodings_test)\n",
    "\n",
    "print(classification_report(mnist_labels_test, y_pred, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6147eb-c7a8-4a42-8340-a31c92b7164e",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b281f96-71b1-4012-8434-bc3486a9680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=300)\n",
    "clf.fit(mnist_encodings, mnist_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b2fa8-4b97-4420-8348-2ad181e64de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(mnist_encodings_test)\n",
    "\n",
    "print(classification_report(mnist_labels_test, y_pred, output_dict=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebdbedf-4286-4309-b1e2-2860ca56b47b",
   "metadata": {},
   "source": [
    "GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c9d07-118b-4350-8bb4-1148ca350223",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "\n",
    "all_classes = list(range(len(np.unique(mnist_labels_test))))\n",
    "                   \n",
    "for item, label in tqdm(zip(mnist_encodings_test, mnist_labels_test), total=len(mnist_labels_test)):\n",
    "    clf.partial_fit(item.reshape(1, -1), [label], classes=all_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c3a91-ef99-4992-89af-efe94aeafb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(mnist_encodings_test)\n",
    "\n",
    "is_correct = y_pred == mnist_labels_test\n",
    "\n",
    "print(classification_report(mnist_labels_test, y_pred, output_dict=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aec491-ca96-437b-9b4b-b9be47231cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(20, 8), nrows=1, ncols=2)\n",
    "\n",
    "ax_test = sns.scatterplot(\n",
    "    x=X_embedded_test[:, 0],\n",
    "    y=X_embedded_test[:, 1],\n",
    "    hue=mnist_labels_test,\n",
    "    style=is_correct,\n",
    "    size=[50 if item else 100 for item in is_correct],\n",
    "    palette=\"gist_rainbow\",\n",
    "    ax=axs[1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a76592-544b-4f0d-bfa9-e792caa45963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_example_from_nb(model, class_to_sample: int, examples_count: int = 1):\n",
    "    class_mean = model.theta_[class_to_sample]\n",
    "    class_std = np.sqrt(model.var_[class_to_sample])\n",
    "    sampled = np.random.normal(loc=class_mean, scale=class_std, size=(examples_count, len(class_mean))).reshape(examples_count, -1)\n",
    "    \n",
    "    proba = model.predict_proba(sampled)[0][class_to_sample]\n",
    "    \n",
    "    sampled = np.clip(sampled, -1, 1)\n",
    "    return sampled\n",
    "\n",
    "\n",
    "sampled = generate_example_from_nb(clf, 9, examples_count=1)\n",
    "print(sampled.shape)\n",
    "reconstruction = autoencoder.model.decode(torch.tensor(sampled).float()).detach().reshape(28, 28).numpy()\n",
    "\n",
    "plt.imshow(reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca90a9-1cc8-4a3e-afb0-b2d9c6f23310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(nb_model, classes_to_sample, shuffle: bool = True) -> torch.tensor:\n",
    "    generated_examples = []\n",
    "    generated_labels = []\n",
    "    for class_index, examples_count in classes_to_sample.items():\n",
    "        generated_example = generate_example_from_nb(nb_model, class_index, examples_count)\n",
    "        generated_tensor = torch.from_numpy(generated_example)\n",
    "        generated_examples.append(generated_tensor)\n",
    "        generated_labels.extend([class_index] * examples_count)\n",
    "    \n",
    "    batch = torch.cat(generated_examples, dim=0).float()\n",
    "    labels = torch.tensor(generated_labels)\n",
    "    \n",
    "    if shuffle:\n",
    "        indexes_shuffled = torch.randperm(len(labels))\n",
    "        batch = batch[indexes_shuffled].view(batch.size())\n",
    "        labels = labels[indexes_shuffled]\n",
    "    \n",
    "    return batch, labels\n",
    "\n",
    "\n",
    "generate_batch(clf, {1: 2, 2: 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e439ee24-6046-44e4-aa8d-d0a4b4e7e7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
